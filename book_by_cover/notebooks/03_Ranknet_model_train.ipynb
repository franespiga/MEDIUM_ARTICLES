{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecc48d9-0d8e-4ca4-ab1d-3292335d341c",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The purpose of this notebook is to generate a RankNet dataset to train a scoring model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad2d95",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cloudpickle\n",
    "import pickle\n",
    "import re\n",
    "import jsonlines\n",
    "from tqdm import tqdm \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51e5be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/DeepESP/gpt2-spanish-medium\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "output = query({\n",
    "\t\"inputs\": \"La m√∫sica no estaba.\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "292b2c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'unknown error',\n",
       " 'warnings': [\"'GPT2Config' object has no attribute 'typical_p'\",\n",
       "  'Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6ce48-8369-4ee9-b6c7-b69af23c5464",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7df246a-6a13-47a8-ba4d-cc7c2662f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "#cambiar a relu\n",
    "def generate_backbone(a_input_size, layers = [64,32,16]):\n",
    "    input_query = tf.keras.layers.Input(shape=[a_input_size,],dtype=tf.float32,name=\"a\")\n",
    "    dense_query = tf.keras.layers.Dense(256, activation=activation)(input_query)\n",
    "    dense_query = tf.keras.layers.Dropout(0.1)(dense_query)\n",
    "\n",
    "    for units in layers:\n",
    "        dense_query = tf.keras.layers.Dense(units, activation=activation)(dense_query)\n",
    "        dense_query = tf.keras.layers.Dropout(0.1)(dense_query)\n",
    "\n",
    "    dense_query = tf.keras.layers.BatchNormalization()(dense_query)\n",
    "    dense_query = tf.keras.layers.Dense(8,activation=activation)(dense_query)\n",
    "    output = tf.keras.layers.Dense(1,activation=\"linear\")(dense_query)\n",
    "    model = tf.keras.models.Model(input_query,output)\n",
    "    return model\n",
    "\n",
    "def ranknet(model, a_input_size, b_input_size):\n",
    "    input_a = tf.keras.layers.Input(shape=[b_input_size,],dtype=tf.float32,name=\"a\")\n",
    "    input_b = tf.keras.layers.Input(shape=[b_input_size,],dtype=tf.float32,name=\"b\")\n",
    "    \n",
    "    o_positive = model(input_a)\n",
    "    o_negative = model(input_b)\n",
    "    o_positive_minus_negative = tf.keras.layers.Subtract()([o_positive,o_negative])\n",
    "    \n",
    "    output = tf.keras.layers.Activation('sigmoid')(o_positive_minus_negative)\n",
    "    \n",
    "    model = tf.keras.models.Model([input_a,input_b],output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9caf943-bcf7-41c6-9d25-ea93d37a487b",
   "metadata": {},
   "source": [
    "### Backbone (underlying ranking model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "382d2b3b-ab27-4b8a-9bcd-9e3cc0bd0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " a (InputLayer)              [(None, 1280)]            0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               327936    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 347,201\n",
      "Trainable params: 347,169\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = generate_backbone(1280)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574f3ec-446e-4b2d-87f8-36490577fe40",
   "metadata": {},
   "source": [
    "### Ranknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1288096a-0aaa-48e5-a9b6-f421257f7105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " a (InputLayer)                 [(None, 1280)]       0           []                               \n",
      "                                                                                                  \n",
      " b (InputLayer)                 [(None, 1280)]       0           []                               \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 1)            347201      ['a[0][0]',                      \n",
      "                                                                  'b[0][0]']                      \n",
      "                                                                                                  \n",
      " subtract_1 (Subtract)          (None, 1)            0           ['model_2[0][0]',                \n",
      "                                                                  'model_2[1][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1)            0           ['subtract_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 347,201\n",
      "Trainable params: 347,169\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ranknet_model = ranknet(model, 1280, 1280)\n",
    "ranknet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32111df5-7c36-4cfc-8e89-f1fca4c08355",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2c192c8-f03c-497e-9a9d-2f27d387f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'a':tf.io.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "    'b': tf.io.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "    'label': tf.io.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "}\n",
    "\n",
    "    \n",
    "@tf.function\n",
    "def _parse_example(example_proto, with_similarity :bool = False):\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    a = tf.io.parse_tensor(example['a'], tf.float32)\n",
    "    b = tf.io.parse_tensor(example['b'],tf.float32)\n",
    "    label = tf.io.parse_tensor(example['label'],tf.float32)\n",
    "        \n",
    "    return (a, b), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bfaa50c-9bd5-41e9-9f75-9b5b3c6e0b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(1280,), dtype=float32, numpy=\n",
       "  array([-2.2389114e-23, -2.1989489e-22, -3.3821736e-18, ...,\n",
       "          2.5871570e+00,  0.0000000e+00, -4.3819432e-28], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1280,), dtype=float32, numpy=\n",
       "  array([-2.2389114e-23, -2.1989489e-22, -3.3821736e-18, ...,\n",
       "          2.5871570e+00,  0.0000000e+00, -4.3819432e-28], dtype=float32)>),\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(filenames = ['cover_ranknet.tfrecords'])\n",
    "train_dataset = train_dataset.map(lambda x: _parse_example(x, True))\n",
    "for i in train_dataset:\n",
    "    break\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2aaa1cb2-7290-425d-a2f0-71b5b4381594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/201 [==============================] - 4s 12ms/step - loss: 0.6166\n",
      "Epoch 2/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5950\n",
      "Epoch 3/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5903\n",
      "Epoch 4/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5875\n",
      "Epoch 5/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5883\n",
      "Epoch 6/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5819\n",
      "Epoch 7/100\n",
      "201/201 [==============================] - 3s 14ms/step - loss: 0.5837\n",
      "Epoch 8/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5832\n",
      "Epoch 9/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5825\n",
      "Epoch 10/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5818\n",
      "Epoch 11/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5801\n",
      "Epoch 12/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5814\n",
      "Epoch 13/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5813\n",
      "Epoch 14/100\n",
      "201/201 [==============================] - 3s 14ms/step - loss: 0.5790\n",
      "Epoch 15/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5803\n",
      "Epoch 16/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5788\n",
      "Epoch 17/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5779\n",
      "Epoch 18/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5759\n",
      "Epoch 19/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5750\n",
      "Epoch 20/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5737\n",
      "Epoch 21/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5740\n",
      "Epoch 22/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5739\n",
      "Epoch 23/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5735\n",
      "Epoch 24/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5726\n",
      "Epoch 25/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5730\n",
      "Epoch 26/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5717\n",
      "Epoch 27/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5725\n",
      "Epoch 28/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5727\n",
      "Epoch 29/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5724\n",
      "Epoch 30/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5724\n",
      "Epoch 31/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5713\n",
      "Epoch 32/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5705\n",
      "Epoch 33/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5688\n",
      "Epoch 34/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5675\n",
      "Epoch 35/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5676\n",
      "Epoch 36/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5740\n",
      "Epoch 37/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5711\n",
      "Epoch 38/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5702\n",
      "Epoch 39/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5691\n",
      "Epoch 40/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5702\n",
      "Epoch 41/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5683\n",
      "Epoch 42/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5677\n",
      "Epoch 43/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5659\n",
      "Epoch 44/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5658\n",
      "Epoch 45/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5661\n",
      "Epoch 46/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5649\n",
      "Epoch 47/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5644\n",
      "Epoch 48/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5639\n",
      "Epoch 49/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5627\n",
      "Epoch 50/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5629\n",
      "Epoch 51/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5623\n",
      "Epoch 52/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5600\n",
      "Epoch 53/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5624\n",
      "Epoch 54/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5606\n",
      "Epoch 55/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5613\n",
      "Epoch 56/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5602\n",
      "Epoch 57/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5586\n",
      "Epoch 58/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5578\n",
      "Epoch 59/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5588\n",
      "Epoch 60/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5584\n",
      "Epoch 61/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5573\n",
      "Epoch 62/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5588\n",
      "Epoch 63/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5578\n",
      "Epoch 64/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5565\n",
      "Epoch 65/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5563\n",
      "Epoch 66/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5568\n",
      "Epoch 67/100\n",
      "201/201 [==============================] - 3s 14ms/step - loss: 0.5553\n",
      "Epoch 68/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5552\n",
      "Epoch 69/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5555\n",
      "Epoch 70/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5550\n",
      "Epoch 71/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5556\n",
      "Epoch 72/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5541\n",
      "Epoch 73/100\n",
      "201/201 [==============================] - 3s 14ms/step - loss: 0.5547\n",
      "Epoch 74/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5538\n",
      "Epoch 75/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5546\n",
      "Epoch 76/100\n",
      "201/201 [==============================] - 3s 14ms/step - loss: 0.5544\n",
      "Epoch 77/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5535\n",
      "Epoch 78/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5529\n",
      "Epoch 79/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5530\n",
      "Epoch 80/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5529\n",
      "Epoch 81/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5526\n",
      "Epoch 82/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5532\n",
      "Epoch 83/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5516\n",
      "Epoch 84/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5522\n",
      "Epoch 85/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5529\n",
      "Epoch 86/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5517\n",
      "Epoch 87/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5510\n",
      "Epoch 88/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5511\n",
      "Epoch 89/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5507\n",
      "Epoch 90/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5508\n",
      "Epoch 91/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5503\n",
      "Epoch 92/100\n",
      "201/201 [==============================] - 2s 12ms/step - loss: 0.5509\n",
      "Epoch 93/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5497\n",
      "Epoch 94/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5505\n",
      "Epoch 95/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5492\n",
      "Epoch 96/100\n",
      "201/201 [==============================] - 3s 13ms/step - loss: 0.5491\n",
      "Epoch 97/100\n",
      "201/201 [==============================] - 2s 11ms/step - loss: 0.5496\n",
      "Epoch 98/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5504\n",
      "Epoch 99/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5486\n",
      "Epoch 100/100\n",
      "201/201 [==============================] - 3s 12ms/step - loss: 0.5483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82e9e57790>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 15*BATCH_SIZE\n",
    "\n",
    "ranknet_model.fit(train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "866b2060-fcac-4d46-8c55-057487096068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 11:04:26.124561: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cover_ranker/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cover_ranker/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./cover_ranker')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
